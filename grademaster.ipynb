{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from ast import alias\n",
        "from concurrent.futures import process\n",
        "from django.shortcuts import render\n",
        "# Create your views here.\n",
        "from django.shortcuts import render, HttpResponse\n",
        "from django.contrib import messages\n",
        "import Automatic_English_Essay_Scoring_Algorithm_Based_On_Ml\n",
        "from .forms import UserRegistrationForm\n",
        "from .models import UserRegistrationModel\n",
        "from django.conf import settings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as plticker\n",
        "import datetime as dt\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "# Create your views here.\n",
        "def UserRegisterActions(request):\n",
        "    if request.method == 'POST':\n",
        "        form = UserRegistrationForm(request.POST)\n",
        "        if form.is_valid():\n",
        "            print('Data is Valid')\n",
        "            form.save()\n",
        "            messages.success(request, 'You have been successfully registered')\n",
        "            form = UserRegistrationForm()\n",
        "            return render(request, 'UserRegistrations.html', {'form': form})\n",
        "        else:\n",
        "            messages.success(request, 'Email or Mobile Already Existed')\n",
        "            print(\"Invalid form\")\n",
        "    else:\n",
        "        form = UserRegistrationForm()\n",
        "    return render(request, 'UserRegistrations.html', {'form': form})\n",
        "def UserLoginCheck(request):\n",
        "    if request.method == \"POST\":\n",
        "        loginid = request.POST.get('loginid')\n",
        "        pswd = request.POST.get('pswd')\n",
        "        print(\"Login ID = \", loginid, ' Password = ', pswd)\n",
        "        try:\n",
        "            check = UserRegistrationModel.objects.get(\n",
        "                loginid=loginid, password=pswd)\n",
        "            status = check.status\n",
        "            print('Status is = ', status)\n",
        "            if status == \"activated\":\n",
        "                request.session['id'] = check.id\n",
        "                request.session['loggeduser'] = check.name\n",
        "                request.session['loginid'] = loginid\n",
        "                request.session['email'] = check.email\n",
        "                print(\"User id At\", check.id, status)\n",
        "                return render(request, 'users/UserHomePage.html', {})\n",
        "            else:\n",
        "                messages.success(request, 'Your Account Not at activated')\n",
        "                return render(request, 'UserLogin.html')\n",
        "        except Exception as e:\n",
        "            print('Exception is ', str(e))\n",
        "            pass\n",
        "        messages.success(request, 'Invalid Login id and password')\n",
        "    return render(request, 'UserLogin.html', {})\n",
        "def UserHome(request):\n",
        "    return render(request, 'users/UserHomePage.html', {})\n",
        "def DatasetView(request):\n",
        "    df = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
        "    df.dropna(axis=1,inplace=True)\n",
        "    df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
        "    df.head()\n",
        "    temp = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Processed_data.csv\")\n",
        "    temp.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
        "    return render(request, 'users/viewdataset.html', {'data': df})\n",
        "def training(request):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import nltk\n",
        "    import re\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "    from gensim.models import Word2Vec\n",
        "    from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "    from keras.models import Sequential, load_model, model_from_config\n",
        "    import keras.backend as K\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import cohen_kappa_score\n",
        "    df = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
        "    df.dropna(axis=1,inplace=True) df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
        "    df.head()\n",
        "    temp = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Processed_data.csv\")\n",
        "    temp.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
        "    df['domain1_score']=temp['final_score']\n",
        "    df.head()\n",
        "    df['essay'][0]\n",
        "    temp.head(1)\n",
        "    #Make Dataset\n",
        "    y = df['domain1_score']\n",
        "    df.drop('domain1_score',inplace=True,axis=1)\n",
        "    X=df\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    X_train.shape\n",
        "    train_e = X_train['essay'].tolist()\n",
        "    test_e = X_test['essay'].tolist()\n",
        "    train_sents=[]\n",
        "    test_sents=[]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    def sent2word(x):\n",
        "        x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
        "        x.lower()\n",
        "        filtered_sentence = []\n",
        "        words=x.split()\n",
        "        for w in words:\n",
        "            if w not in stop_words:\n",
        "                filtered_sentence.append(w)\n",
        "        return filtered_sentence\n",
        "    def essay2word(essay):\n",
        "        essay = essay.strip()\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        raw = tokenizer.tokenize(essay)\n",
        "        final_words=[]\n",
        "        for i in raw:\n",
        "            if(len(i)>0):\n",
        "                final_words.append(sent2word(i))\n",
        "        return final_words\n",
        "    for i in train_e:\n",
        "        train_sents+=essay2word(i)\n",
        "    for i in test_e:\n",
        "        test_sents+=essay2word(i)\n",
        "    len(train_sents)\n",
        "    train_sents[0]\n",
        "    def get_model():\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "        model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1, activation='relu'))\n",
        "        model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "        model.summary()\n",
        "        return model\n",
        "    #Training Word2Vec model\n",
        "    num_features = 300\n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "    model = Word2Vec(train_sents,\n",
        "                    workers=num_workers,\n",
        "                    vector_size=num_features,  # Use 'vector_size' instead of 'size'\n",
        "                    min_count=min_word_count,\n",
        "                    window=context,\n",
        "                    sample=downsampling)\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "    def makeVec(words, model, num_features):\n",
        "        vec = np.zeros((num_features,), dtype=\"float32\")\n",
        "        noOfWords = 0.0\n",
        "        for i in words:\n",
        "            if i in model.wv:\n",
        "                noOfWords += 1\n",
        "                vec = np.add(vec, model.wv.get_vector(i))\n",
        "        if noOfWords > 0:\n",
        "            vec = np.divide(vec, noOfWords)\n",
        "        return vec\n",
        "    def getVecs(essays, model, num_features):\n",
        "        essay_vecs = np.zeros((len(essays), num_features), dtype=\"float32\")\n",
        "        for c, essay in enumerate(essays):\n",
        "            essay_vecs[c] = makeVec(essay, model, num_features)\n",
        "        return essay_vecs\n",
        "    clean_train = []\n",
        "    for i in train_e:\n",
        "        clean_train.append(sent2word(i))\n",
        "    training_vectors = getVecs(clean_train, model, num_features)\n",
        "    clean_test = []\n",
        "    for i in test_e:\n",
        "        clean_test.append(sent2word(i))\n",
        "    testing_vectors = getVecs(clean_test, model, num_features)\n",
        "    training_vectors.shape\n",
        "    training_vectors = np.array(training_vectors)\n",
        "    testing_vectors = np.array(testing_vectors)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
        "    testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
        "    lstm_model = get_model()\n",
        "    training_vectors.shape\n",
        "    lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)\n",
        "    loss,mea = lstm_model.evaluate(testing_vectors,y_test)\n",
        "    lstm_model.save('final_lstm.h5')\n",
        "    y_pred = lstm_model.predict(testing_vectors)\n",
        "    y_pred = np.around(y_pred)\n",
        "    y_pred\n",
        "    return render(request,\"users/training.html\",{'loss':loss,'mean_absolute_error':mea}) #,{\"Accuracy\":eval_accuracy * 100,\"Loss\":eval_loss}\n",
        "def prediction(request):\n",
        "    if request.method=='POST':\n",
        "        final_text = request.POST.get('final_text')\n",
        "        from flask import Flask,request,render_template,url_for,jsonify\n",
        "        import site\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        import nltk\n",
        "        import re\n",
        "        from nltk.corpus import stopwords\n",
        "        from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "        from gensim.models import Word2Vec\n",
        "        from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "        from keras.models import Sequential, load_model, model_from_config\n",
        "        import keras.backend as K\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.metrics import mean_squared_error\n",
        "        from sklearn.metrics import cohen_kappa_score\n",
        "        from gensim.models.keyedvectors import KeyedVectors\n",
        "        from keras import backend as K\n",
        "        def sent2word(x):\n",
        "            stop_words = set(stopwords.words('english'))\n",
        "            x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
        "            x.lower()\n",
        "            filtered_sentence = []\n",
        "            words=x.split()\n",
        "            for w in words:\n",
        "                if w not in stop_words:\n",
        "                    filtered_sentence.append(w)\n",
        "            return filtered_sentence\n",
        "        def essay2word(essay):\n",
        "            essay = essay.strip()\n",
        "            tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "            raw = tokenizer.tokenize(essay)\n",
        "            final_words=[]\n",
        "            for i in raw:\n",
        "                if(len(i)>0):\n",
        "                    final_words.append(sent2word(i))\n",
        "            return final_words\n",
        "        def makeVec(words, model, num_features):\n",
        "            vec = np.zeros((num_features,),dtype=\"float32\")\n",
        "            noOfWords = 0.\n",
        "            index2word_set = set(model.index_to_key)\n",
        "            for i in words:\n",
        "                if i in index2word_set:\n",
        "                    noOfWords += 1\n",
        "                    vec = np.add(vec,model[i])\n",
        "            vec = np.divide(vec,noOfWords)\n",
        "            return vec\n",
        "        def getVecs(essays, model, num_features):\n",
        "            c=0\n",
        "            essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "            for i in essays:\n",
        "                essay_vecs[c] = makeVec(i, model, num_features)\n",
        "                c+=1\n",
        "            return essay_vecs\n",
        "        def get_model():\n",
        "            model = Sequential()\n",
        "            model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "            model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(1, activation='relu'))\n",
        "            model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "            model.summary()\n",
        "            return model\n",
        "        def convertToVec(text):\n",
        "            content=text\n",
        "            if len(content) > 20:\n",
        "                num_features = 300\n",
        "                model = KeyedVectors.load_word2vec_format(\"word2vecmodel.bin\", binary=True)\n",
        "                clean_test_essays = []\n",
        "                clean_test_essays.append(sent2word(content))\n",
        "                testDataVecs = getVecs(clean_test_essays, model, num_features )\n",
        "                testDataVecs = np.array(testDataVecs)\n",
        "                testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "                lstm_model = load_model(\"final_lstm.h5\")\n",
        "                preds = lstm_model.predict(testDataVecs)\n",
        "                return str(round(preds[0][0]))\n",
        "        def convertToVec(text):\n",
        "            if text is not None and len(text.strip()) > 20:\n",
        "                content = text\n",
        "                num_features = 300\n",
        "                model = KeyedVectors.load_word2vec_format(\"/content/Automatic-Essay-Scoring/word2vecmodel.bin\", binary=True)\n",
        "                clean_test_essays = []\n",
        "                clean_test_essays.append(sent2word(content))\n",
        "                testDataVecs = getVecs(clean_test_essays, model, num_features)\n",
        "                testDataVecs = np.array(testDataVecs)\n",
        "                testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "                lstm_model = load_model(\"/content/Automatic-Essay-Scoring/final_lstm.h5\")\n",
        "                preds = lstm_model.predict(testDataVecs)\n",
        "                return str(round(preds[0][0]))\n",
        "            else:\n",
        "                # Handle the case where text is None or too short\n",
        "                return \"Unable to calculate a score.\"\n",
        "        score = convertToVec(final_text)\n",
        "        print(score)\n",
        "        return render(request, 'users/predictForm.html', {'score':score})\n",
        "    elsereturn render(request, 'users/predictForm.html', {})\n",
        "base.html:\n",
        "{% load static %}\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\">\n",
        "  <title>Arsha Bootstrap Template - Index</title>\n",
        "  <meta content=\"\" name=\"description\">\n",
        "  <meta content=\"\" name=\"keywords\">\n",
        "  <!-- Favicons -->\n",
        "  <link href=\"{% static 'assets/img/favicon.png' %}\" rel=\"icon\">\n",
        "  <link href=\"{% static 'assets/img/apple-touch-icon.png' %}\" rel=\"apple-touch-icon\">\n",
        "  <!-- Google Fonts -->\n",
        "  <link href=\"https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Jost:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i\" rel=\"stylesheet\">\n",
        "  <!-- Vendor CSS Files -->\n",
        "  <link href=\"{% static 'assets/vendor/aos/aos.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/bootstrap/css/bootstrap.min.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/bootstrap-icons/bootstrap-icons.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/boxicons/css/boxicons.min.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/glightbox/css/glightbox.min.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/remixicon/remixicon.css' %}\" rel=\"stylesheet\">\n",
        "  <link href=\"{% static 'assets/vendor/swiper/swiper-bundle.min.css' %}\" rel=\"stylesheet\">\n",
        "  <!-- Template Main CSS File -->\n",
        "  <link href=\"{% static 'assets/css/style.css' %}\" rel=\"stylesheet\">\n",
        "  <!-- =======================================================\n",
        "  * Template Name: Arsha - v4.11.0\n",
        "  * Template URL: https://bootstrapmade.com/arsha-free-bootstrap-html-template-corporate/\n",
        "  * Author: BootstrapMade.com\n",
        "  * License: https://bootstrapmade.com/license/\n",
        "  ======================================================== -->\n",
        "</head>\n",
        "<body>\n",
        "    <style>\n",
        "        span{\n",
        "            color:white;\n",
        "        }\n",
        "        header{\n",
        "            background-color:GREEN;\n",
        "        }\n",
        "        body{\n",
        "            background-image: url('{% static 'assets/img/essay.jpg' %}');\n",
        "        }\n",
        "    </style>\n",
        "  <!-- ======= Header ======= -->\n",
        "  <header id=\"header\" class=\"fixed-top \">\n",
        "    <div class=\"container d-flex align-items-center\">\n",
        "      <h1 class=\"logo me-auto\"><a href=\"index.html\"><span>Automatic English Essay Scoring</span></a></h1>\n",
        "      <!-- Uncomment below if you prefer to use an image logo -->\n",
        "      <!-- <a href=\"index.html\" class=\"logo me-auto\"><img src=\"assets/img/logo.png\" alt=\"\" class=\"img-fluid\"></a>-->\n",
        "      <nav id=\"navbar\" class=\"navbar\">\n",
        "        <ul>\n",
        "          <li><a class=\"nav-link scrollto active\" href=\"{% url 'index' %}\">Home</a></li>\n",
        "          <li><a class=\"nav-link scrollto\" href=\"{% url 'AdminLogin' %}\">Admin</a></li>\n",
        "          <li><a class=\"nav-link scrollto\" href=\"{% url 'UserLogin' %}\">User</a></li>\n",
        "          <li><a class=\"nav-link   scrollto\" href=\"{% url 'UserRegister' %}\">Register</a></li>\n",
        "        </ul>\n",
        "        <i class=\"bi bi-list mobile-nav-toggle\"></i>\n",
        "      </nav><!-- .navbar -->\n",
        "    </div>\n",
        "  </header><!-- End Header -->\n",
        "{% block contents %}\n",
        "{% endblock %}\n",
        "  <!-- ======= Footer ======= -->\n",
        "  <footer id=\"footer\">\n",
        "  </footer><!-- End Footer -->\n",
        "  <div id=\"preloader\"></div>\n",
        "  <a href=\"#\" class=\"back-to-top d-flex align-items-center justify-content-center\"><i class=\"bi bi-arrow-up-short\"></i></a>\n",
        "  <!-- Vendor JS Files -->\n",
        "  <script src=\"{% static 'assets/vendor/aos/aos.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/bootstrap/js/bootstrap.bundle.min.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/glightbox/js/glightbox.min.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/isotope-layout/isotope.pkgd.min.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/swiper/swiper-bundle.min.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/waypoints/noframework.waypoints.js' %}\"></script>\n",
        "  <script src=\"{% static 'assets/vendor/php-email-form/validate.js' %}\"></script>\n",
        "  <!-- Template Main JS File -->\n",
        "  <script src=\"{% static 'assets/js/main.js' %}\"></script>\n",
        "</body>\n",
        "</html>\n",
        "Admin side views:\n",
        "from django.shortcuts import render\n",
        "from django.contrib import messages\n",
        "from users.forms import UserRegistrationForm\n",
        "from users.models import UserRegistrationModel\n",
        "# Create your views here.\n",
        "def AdminLoginCheck(request):\n",
        "    if request.method == 'POST':\n",
        "        usrid = request.POST.get('loginid')\n",
        "        pswd = request.POST.get('pswd')\n",
        "        print(\"User ID is = \", usrid)\n",
        "        if usrid == 'admin' and pswd == 'admin':\n",
        "            return render(request, 'admins/AdminHome.html')\n",
        "        else:\n",
        "            messages.success(request, 'Please Check Your Login Details')\n",
        "    return render(request, 'AdminLogin.html', {})\n",
        "def AdminHome(request):\n",
        "    return render(request, 'admins/AdminHome.html',{})\n",
        "def RegisterUsersView(request):\n",
        "    data = UserRegistrationModel.objects.all()\n",
        "    return render(request,'admins/viewregisterusers.html',{'data':data})\n",
        "def ActivaUsers(request):\n",
        "    if request.method == 'GET':\n",
        "        id = request.GET.get('uid')\n",
        "        status = 'activated'\n",
        "        print(\"PID = \", id, status)\n",
        "        UserRegistrationModel.objects.filter(id=id).update(status=status)\n",
        "        data = UserRegistrationModel.objects.all()\n",
        "        return render(request,'admins/viewregisterusers.html',{'data':data})\n",
        "\n"
      ],
      "metadata": {
        "id": "INNNcQWTIjY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}